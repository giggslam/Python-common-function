{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "def count_ngrams(lines, min_length=2, max_length=4):\n",
    "    lengths = range(min_length, max_length + 1)\n",
    "    ngrams = { length: collections.Counter() for length in lengths}\n",
    "    queue = collections.deque(maxlen=max_length)\n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['this is a testing']\n",
    "count_ngrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length=2; max_length=4\n",
    "lengths = range(min_length, max_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(2, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/benhoyt/dfafeab26d7c02a52ed17b6229f0cb52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('維', '克') 1\n",
      "('克', '多') 1\n",
      "('多', '雨') 1\n",
      "('雨', '果') 1\n",
      "('果', 'v') 1\n",
      "('v', 'i') 1\n",
      "('i', 'c') 1\n",
      "('c', 't') 1\n",
      "('t', 'o') 1\n",
      "('o', 'r') 1\n",
      "('r', 'h') 1\n",
      "('h', 'u') 1\n",
      "('u', 'g') 1\n",
      "('g', 'o') 1\n",
      "('o', '1') 1\n",
      "('1', '8') 2\n",
      "('8', '0') 1\n",
      "('0', '2') 1\n",
      "('2', '1') 1\n",
      "('8', '8') 1\n",
      "('8', '5') 1\n",
      "('5', '是') 1\n",
      "('是', '法') 1\n",
      "('法', '國') 2\n",
      "('國', '浪') 1\n",
      "('浪', '漫') 2\n",
      "('漫', '主') 2\n",
      "('主', '義') 3\n",
      "('義', '作') 1\n",
      "('作', '家') 3\n",
      "('家', '人') 1\n",
      "('人', '道') 1\n",
      "('道', '主') 1\n",
      "('義', '的') 1\n",
      "('的', '代') 2\n",
      "('代', '表') 2\n",
      "('表', '人') 1\n",
      "('人', '物') 1\n",
      "('物', '1') 1\n",
      "('1', '9') 1\n",
      "('9', '世') 1\n",
      "('世', '紀') 1\n",
      "('紀', '前') 1\n",
      "('前', '期') 1\n",
      "('期', '積') 1\n",
      "('積', '極') 1\n",
      "('極', '浪') 1\n",
      "('義', '文') 1\n",
      "('文', '學') 4\n",
      "('學', '運') 1\n",
      "('運', '動') 1\n",
      "('動', '的') 1\n",
      "('表', '作') 1\n",
      "('家', '法') 1\n",
      "('國', '文') 1\n",
      "('學', '史') 1\n",
      "('史', '上') 1\n",
      "('上', '卓') 1\n",
      "('卓', '越') 1\n",
      "('越', '的') 1\n",
      "('的', '資') 1\n",
      "('資', '產') 1\n",
      "('產', '階') 1\n",
      "('階', '級') 1\n",
      "('級', '民') 1\n",
      "('民', '主') 1\n",
      "('主', '作') 1\n",
      "('家', '被') 1\n",
      "('被', '人') 1\n",
      "('人', '們') 1\n",
      "('們', '稱') 1\n",
      "('稱', '為') 1\n",
      "('為', '法') 1\n",
      "('法', '蘭') 1\n",
      "('蘭', '西') 1\n",
      "('西', '的') 1\n",
      "('的', '莎') 1\n",
      "('莎', '士') 1\n",
      "('士', '比') 1\n",
      "('比', '亞') 1\n",
      "('亞', '他') 1\n",
      "('他', '的') 1\n",
      "('的', '文') 1\n",
      "('學', '鉅') 1\n",
      "('鉅', '著') 1\n",
      "('著', '巴') 1\n",
      "('巴', '黎') 1\n",
      "('黎', '聖') 1\n",
      "('聖', '母') 1\n",
      "('母', '院') 1\n",
      "('院', '悲') 1\n",
      "('悲', '慘') 1\n",
      "('慘', '世') 1\n",
      "('世', '界') 2\n",
      "('界', '九') 1\n",
      "('九', '三') 1\n",
      "('三', '年') 1\n",
      "('年', '等') 1\n",
      "('等', '已') 1\n",
      "('已', '成') 1\n",
      "('成', '為') 1\n",
      "('為', '世') 1\n",
      "('界', '文') 1\n",
      "('學', '寶') 1\n",
      "('寶', '庫') 1\n",
      "('庫', '中') 1\n",
      "('中', '的') 1\n",
      "('的', '珍') 1\n",
      "('珍', '貴') 1\n",
      "('貴', '財') 1\n",
      "('財', '富') 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#f = open('a_text_file')\n",
    "#raw = f.read()\n",
    "\n",
    "#tokens = nltk.word_tokenize(raw)\n",
    "#tokens = ['a','a','b','c','a','b']\n",
    "#tokens = ['我','們','是','我','們','的','我','們','的']\n",
    "\n",
    "#Create your bigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "for k,v in fdist.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('浪', '漫', '主'): 2, ('漫', '主', '義'): 2, ('的', '代', '表'): 2, ('維', '克', '多'): 1, ('克', '多', '雨'): 1, ('多', '雨', '果'): 1, ('雨', '果', 'v'): 1, ('果', 'v', 'i'): 1, ('v', 'i', 'c'): 1, ('i', 'c', 't'): 1, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "\n",
    "bigramfdist = FreqDist()\n",
    "bigrams = ngrams(tokens, 3)\n",
    "bigramfdist.update(bigrams)\n",
    "bigramfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('維', '克', '多') 1\n",
      "('克', '多', '雨') 1\n",
      "('多', '雨', '果') 1\n",
      "('雨', '果', 'v') 1\n",
      "('果', 'v', 'i') 1\n",
      "('v', 'i', 'c') 1\n",
      "('i', 'c', 't') 1\n",
      "('c', 't', 'o') 1\n",
      "('t', 'o', 'r') 1\n",
      "('o', 'r', 'h') 1\n",
      "('r', 'h', 'u') 1\n",
      "('h', 'u', 'g') 1\n",
      "('u', 'g', 'o') 1\n",
      "('g', 'o', '1') 1\n",
      "('o', '1', '8') 1\n",
      "('1', '8', '0') 1\n",
      "('8', '0', '2') 1\n",
      "('0', '2', '1') 1\n",
      "('2', '1', '8') 1\n",
      "('1', '8', '8') 1\n",
      "('8', '8', '5') 1\n",
      "('8', '5', '是') 1\n",
      "('5', '是', '法') 1\n",
      "('是', '法', '國') 1\n",
      "('法', '國', '浪') 1\n",
      "('國', '浪', '漫') 1\n",
      "('浪', '漫', '主') 2\n",
      "('漫', '主', '義') 2\n",
      "('主', '義', '作') 1\n",
      "('義', '作', '家') 1\n",
      "('作', '家', '人') 1\n",
      "('家', '人', '道') 1\n",
      "('人', '道', '主') 1\n",
      "('道', '主', '義') 1\n",
      "('主', '義', '的') 1\n",
      "('義', '的', '代') 1\n",
      "('的', '代', '表') 2\n",
      "('代', '表', '人') 1\n",
      "('表', '人', '物') 1\n",
      "('人', '物', '1') 1\n",
      "('物', '1', '9') 1\n",
      "('1', '9', '世') 1\n",
      "('9', '世', '紀') 1\n",
      "('世', '紀', '前') 1\n",
      "('紀', '前', '期') 1\n",
      "('前', '期', '積') 1\n",
      "('期', '積', '極') 1\n",
      "('積', '極', '浪') 1\n",
      "('極', '浪', '漫') 1\n",
      "('主', '義', '文') 1\n",
      "('義', '文', '學') 1\n",
      "('文', '學', '運') 1\n",
      "('學', '運', '動') 1\n",
      "('運', '動', '的') 1\n",
      "('動', '的', '代') 1\n",
      "('代', '表', '作') 1\n",
      "('表', '作', '家') 1\n",
      "('作', '家', '法') 1\n",
      "('家', '法', '國') 1\n",
      "('法', '國', '文') 1\n",
      "('國', '文', '學') 1\n",
      "('文', '學', '史') 1\n",
      "('學', '史', '上') 1\n",
      "('史', '上', '卓') 1\n",
      "('上', '卓', '越') 1\n",
      "('卓', '越', '的') 1\n",
      "('越', '的', '資') 1\n",
      "('的', '資', '產') 1\n",
      "('資', '產', '階') 1\n",
      "('產', '階', '級') 1\n",
      "('階', '級', '民') 1\n",
      "('級', '民', '主') 1\n",
      "('民', '主', '作') 1\n",
      "('主', '作', '家') 1\n",
      "('作', '家', '被') 1\n",
      "('家', '被', '人') 1\n",
      "('被', '人', '們') 1\n",
      "('人', '們', '稱') 1\n",
      "('們', '稱', '為') 1\n",
      "('稱', '為', '法') 1\n",
      "('為', '法', '蘭') 1\n",
      "('法', '蘭', '西') 1\n",
      "('蘭', '西', '的') 1\n",
      "('西', '的', '莎') 1\n",
      "('的', '莎', '士') 1\n",
      "('莎', '士', '比') 1\n",
      "('士', '比', '亞') 1\n",
      "('比', '亞', '他') 1\n",
      "('亞', '他', '的') 1\n",
      "('他', '的', '文') 1\n",
      "('的', '文', '學') 1\n",
      "('文', '學', '鉅') 1\n",
      "('學', '鉅', '著') 1\n",
      "('鉅', '著', '巴') 1\n",
      "('著', '巴', '黎') 1\n",
      "('巴', '黎', '聖') 1\n",
      "('黎', '聖', '母') 1\n",
      "('聖', '母', '院') 1\n",
      "('母', '院', '悲') 1\n",
      "('院', '悲', '慘') 1\n",
      "('悲', '慘', '世') 1\n",
      "('慘', '世', '界') 1\n",
      "('世', '界', '九') 1\n",
      "('界', '九', '三') 1\n",
      "('九', '三', '年') 1\n",
      "('三', '年', '等') 1\n",
      "('年', '等', '已') 1\n",
      "('等', '已', '成') 1\n",
      "('已', '成', '為') 1\n",
      "('成', '為', '世') 1\n",
      "('為', '世', '界') 1\n",
      "('世', '界', '文') 1\n",
      "('界', '文', '學') 1\n",
      "('文', '學', '寶') 1\n",
      "('學', '寶', '庫') 1\n",
      "('寶', '庫', '中') 1\n",
      "('庫', '中', '的') 1\n",
      "('中', '的', '珍') 1\n",
      "('的', '珍', '貴') 1\n",
      "('珍', '貴', '財') 1\n",
      "('貴', '財', '富') 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in bigramfdist.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams    \n",
    "def compute_freq():\n",
    "   textfile = open('corpus.txt','r')\n",
    "\n",
    "   bigramfdist = FreqDist()\n",
    "   threeramfdist = FreqDist()\n",
    "\n",
    "   for line in textfile:\n",
    "        if len(line) > 1:\n",
    "        tokens = line.strip().split(' ')\n",
    "\n",
    "        bigrams = ngrams(tokens, 2)\n",
    "        bigramfdist.update(bigrams)\n",
    "compute_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def tokenize(string):\n",
    "    \"\"\"Convert string to lowercase and split into words (ignoring\n",
    "    punctuation), returning list of words.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\w+', string.lower())\n",
    "\n",
    "\n",
    "def count_ngrams(lines, min_length=2, max_length=4):\n",
    "    \"\"\"Iterate through given lines iterator (file object or list of\n",
    "    lines) and return n-gram frequencies. The return value is a dict\n",
    "    mapping the length of the n-gram to a collections.Counter\n",
    "    object of n-gram tuple and number of times that n-gram occurred.\n",
    "    Returned dict includes n-grams of length min_length to max_length.\n",
    "    \"\"\"\n",
    "    lengths = range(min_length, max_length + 1)\n",
    "    ngrams = {length: collections.Counter() for length in lengths}\n",
    "    queue = collections.deque(maxlen=max_length)\n",
    "\n",
    "    # Helper function to add n-grams at start of current queue to dict\n",
    "    def add_queue():\n",
    "        current = tuple(queue)\n",
    "        for length in lengths:\n",
    "            if len(current) >= length:\n",
    "                ngrams[length][current[:length]] += 1\n",
    "\n",
    "    # Loop through all lines and words and add n-grams to dict\n",
    "    for line in lines:\n",
    "        for word in tokenize(line):\n",
    "            queue.append(word)\n",
    "            if len(queue) >= max_length:\n",
    "                add_queue()\n",
    "\n",
    "    # Make sure we get the n-grams at the tail end of the queue\n",
    "    while len(queue) > min_length:\n",
    "        queue.popleft()\n",
    "        add_queue()\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def print_most_frequent(ngrams, num=10):\n",
    "    \"\"\"Print num most common n-grams of each length in n-grams dict.\"\"\"\n",
    "    for n in sorted(ngrams):\n",
    "        print('----- {} most common {}-grams -----'.format(num, n))\n",
    "        for gram, count in ngrams[n].most_common(num):\n",
    "            print('{0}: {1}'.format(' '.join(gram), count))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 20 most common 2-grams -----\n",
      "馬可 波羅遊記: 26\n",
      "馬丁 路德: 8\n",
      "堂 吉訶德: 8\n",
      "路德 金: 4\n",
      "馬克 吐溫: 4\n",
      "是年 發表了: 4\n",
      "克拉克 蓋博: 4\n",
      "e t: 4\n",
      "t 外星人: 4\n",
      "說下去 你說: 3\n",
      "戴爾 卡耐基: 3\n",
      "西奧多 羅斯福: 3\n",
      "不是由弱者而是由強者表現出來時 才為人推崇: 3\n",
      "恰爾德 哈羅德遊記: 3\n",
      "安娜 卡列尼娜: 3\n",
      "湯姆 索亞歷險記: 3\n",
      "歐 亨利: 3\n",
      "永別了 武器: 3\n",
      "海倫 凱勒: 3\n",
      "達 芬奇: 3\n",
      "\n",
      "----- 20 most common 3-grams -----\n",
      "e t 外星人: 4\n",
      "馬丁 路德 金: 3\n",
      "少時隨父親哈米爾卡 巴卡進軍西班牙 並在父親面前發下一生的誓言: 2\n",
      "巴卡進軍西班牙 並在父親面前發下一生的誓言 要終身與羅馬為敵: 2\n",
      "法國文學史上卓越的資產階級民主作家 被人們稱為 法蘭西的莎士比亞: 2\n",
      "被人們稱為 法蘭西的莎士比亞 他的文學鉅著: 2\n",
      "法蘭西的莎士比亞 他的文學鉅著 巴黎聖母院: 2\n",
      "他的文學鉅著 巴黎聖母院 悲慘世界: 2\n",
      "巴黎聖母院 悲慘世界 九三年: 2\n",
      "悲慘世界 九三年 等: 2\n",
      "九三年 等 已成為世界文學寶庫中的珍貴財富: 2\n",
      "蒙娜麗莎 最後的晚餐 巖間聖母: 2\n",
      "他的財富更是一個神話 39歲便成為世界首富 並連續13年登上福布斯榜首的位置: 2\n",
      "我聽到一個聲音 要求我放棄一切 跟隨基督進入貧民窟: 2\n",
      "要求我放棄一切 跟隨基督進入貧民窟 以便我能在最窮的窮人當中服侍他: 2\n",
      "跟隨基督進入貧民窟 以便我能在最窮的窮人當中服侍他 我知道這是他的意思: 2\n",
      "以便我能在最窮的窮人當中服侍他 我知道這是他的意思 我要照辦: 2\n",
      "一個國家的公正與寬巨集 如同一個人的公正與寬巨集一樣 不是由弱者而是由強者表現出來時: 2\n",
      "如同一個人的公正與寬巨集一樣 不是由弱者而是由強者表現出來時 才為人推崇: 2\n",
      "真正的英雄 是即使膽怯 也照樣勇敢作戰的男子漢: 2\n",
      "\n",
      "----- 20 most common 4-grams -----\n",
      "少時隨父親哈米爾卡 巴卡進軍西班牙 並在父親面前發下一生的誓言 要終身與羅馬為敵: 2\n",
      "法國文學史上卓越的資產階級民主作家 被人們稱為 法蘭西的莎士比亞 他的文學鉅著: 2\n",
      "被人們稱為 法蘭西的莎士比亞 他的文學鉅著 巴黎聖母院: 2\n",
      "法蘭西的莎士比亞 他的文學鉅著 巴黎聖母院 悲慘世界: 2\n",
      "他的文學鉅著 巴黎聖母院 悲慘世界 九三年: 2\n",
      "巴黎聖母院 悲慘世界 九三年 等: 2\n",
      "悲慘世界 九三年 等 已成為世界文學寶庫中的珍貴財富: 2\n",
      "我聽到一個聲音 要求我放棄一切 跟隨基督進入貧民窟 以便我能在最窮的窮人當中服侍他: 2\n",
      "要求我放棄一切 跟隨基督進入貧民窟 以便我能在最窮的窮人當中服侍他 我知道這是他的意思: 2\n",
      "跟隨基督進入貧民窟 以便我能在最窮的窮人當中服侍他 我知道這是他的意思 我要照辦: 2\n",
      "一個國家的公正與寬巨集 如同一個人的公正與寬巨集一樣 不是由弱者而是由強者表現出來時 才為人推崇: 2\n",
      "真正的英雄 是即使膽怯 也照樣勇敢作戰的男子漢 有的戰士在火線上不到一分鐘: 2\n",
      "是即使膽怯 也照樣勇敢作戰的男子漢 有的戰士在火線上不到一分鐘 便會克服恐懼: 2\n",
      "也照樣勇敢作戰的男子漢 有的戰士在火線上不到一分鐘 便會克服恐懼 有的要一小時: 2\n",
      "但是 真正的男子漢 不會讓對死亡的恐懼戰勝榮譽感 責任感和雄風: 2\n",
      "仲夏夜之夢 威尼斯商人 亨利四世 第十二夜: 2\n",
      "威尼斯商人 亨利四世 第十二夜 裘力斯: 2\n",
      "亨利四世 第十二夜 裘力斯 愷撒: 2\n",
      "第十二夜 裘力斯 愷撒 哈姆雷特: 2\n",
      "青春的苦惱 抒情插曲 還鄉集 北海集: 2\n",
      "\n",
      "Took 0.145 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "textfile = 'data/chatbot_challenge.revised2.txt'\n",
    "with open(textfile) as f:\n",
    "    ngrams = count_ngrams(f)\n",
    "print_most_frequent(ngrams)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Took {:.03f} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['維克多', '雨果', 'victor', 'hugo', '1802', '1885', '是法國浪漫主義作家', '人道主義的代表人物', '19世紀前期積極浪漫主義文學運動的代表作家', '法國文學史上卓越的資產階級民主作家', '被人們稱為', '法蘭西的莎士比亞', '他的文學鉅著', '巴黎聖母院', '悲慘世界', '九三年', '等', '已成為世界文學寶庫中的珍貴財富']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(string):\n",
    "    \"\"\"Convert string to lowercase and split into words (ignoring\n",
    "    punctuation), returning list of words.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\w+', string.lower())\n",
    "text = \"維克多·雨果（victor hugo，1802—1885）是法國浪漫主義作家，人道主義的代表人物，19世紀前期積極浪漫主義文學運動的代表作家，法國文學史上卓越的資產階級民主作家，被人們稱為“法蘭西的莎士比亞”。他的文學鉅著《巴黎聖母院》《悲慘世界》《九三年》等，已成為世界文學寶庫中的珍貴財富。\"\n",
    "print(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "維克多\n",
      "雨果\n",
      "victor\n",
      "hugo\n",
      "1802\n",
      "1885\n",
      "是法國浪漫主義作家\n",
      "人道主義的代表人物\n",
      "19世紀前期積極浪漫主義文學運動的代表作家\n",
      "法國文學史上卓越的資產階級民主作家\n",
      "被人們稱為\n",
      "法蘭西的莎士比亞\n",
      "他的文學鉅著\n",
      "巴黎聖母院\n",
      "悲慘世界\n",
      "九三年\n",
      "等\n",
      "已成為世界文學寶庫中的珍貴財富\n"
     ]
    }
   ],
   "source": [
    "def tokenization_char(text):\n",
    "    chars = []\n",
    "    text = re.findall(r'\\w+', text.lower())\n",
    "    for phrase in text:\n",
    "        print(phrase)\n",
    "        for w in phrase:\n",
    "            #keep english word & number, not spilt, TODO\n",
    "            chars.append(w)\n",
    "    return chars\n",
    "\n",
    "#for w in text:\n",
    "#    print(w)\n",
    "chars = tokenization_char(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
